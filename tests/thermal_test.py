#!/usr/bin/env python3
"""Thermal Stress Test - Check cooling and temperature limits"""

import torch
import subprocess
import argparse
import sys
import time

def get_temperature():
    """Get current GPU temperature"""
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=temperature.gpu", "--format=csv,noheader"],
            capture_output=True, text=True, check=True
        )
        return int(result.stdout.strip())
    except:
        return None

def thermal_stress_test(duration_minutes=3, temp_limit_gpu=85):
    """
    Thermal stress test with temperature monitoring
    
    Args:
        duration_minutes: Test duration in minutes
        temp_limit_gpu: GPU temperature limit (Â°C)
    """
    
    print("=" * 60)
    print("THERMAL STRESS TEST")
    print("=" * 60)
    
    if not torch.cuda.is_available():
        print("âŒ CUDA not available!")
        return False
    
    device = torch.device("cuda:0")
    gpu_name = torch.cuda.get_device_name(0)
    
    print(f"\nğŸ”§ GPU: {gpu_name}")
    print(f"â±ï¸  Duration: {duration_minutes} minutes")
    print(f"ğŸŒ¡ï¸  Temperature limit: {temp_limit_gpu}Â°C GPU")
    print("-" * 60)
    
    # Get initial temperature
    start_temp = get_temperature()
    if start_temp:
        print(f"\nğŸ“Š Starting temperature: {start_temp}Â°C")
    
    # Create workload
    print(f"\n1ï¸âƒ£  Creating thermal workload...")
    size = 8192
    
    try:
        # Allocate tensors
        tensor_a = torch.randn(size, size, device=device, dtype=torch.float32)
        tensor_b = torch.randn(size, size, device=device, dtype=torch.float32)
        
        print(f"   âœ“ Workload created ({size}x{size} matrices)")
        
        # Stress test
        print(f"\n2ï¸âƒ£  Running thermal stress test...")
        print("   Monitoring temperature every 10 seconds\n")
        
        start_time = time.time()
        test_duration = duration_minutes * 60
        iterations = 0
        
        max_temp = 0
        temps = []
        throttled = False
        
        while (time.time() - start_time) < test_duration:
            # Compute-intensive operations
            for _ in range(50):
                result = torch.matmul(tensor_a, tensor_b)
                result = torch.matmul(result, tensor_b)
            
            iterations += 1
            
            # Check temperature every 10 seconds
            if iterations % 5 == 0:
                current_temp = get_temperature()
                if current_temp:
                    temps.append(current_temp)
                    max_temp = max(max_temp, current_temp)
                    
                    elapsed = time.time() - start_time
                    progress = (elapsed / test_duration) * 100
                    
                    # Temperature indicator
                    if current_temp < 75:
                        temp_status = "âœ“ GOOD"
                    elif current_temp < 80:
                        temp_status = "âš  WARM"
                    elif current_temp < temp_limit_gpu:
                        temp_status = "âš  HOT"
                    else:
                        temp_status = "âŒ TOO HOT"
                        throttled = True
                    
                    print(f"   [{progress:5.1f}%] Temp: {current_temp:3d}Â°C | {temp_status}")
        
        # Results
        print(f"\n3ï¸âƒ£  Test completed!")
        print(f"   Iterations: {iterations}")
        print(f"   Max temperature: {max_temp}Â°C")
        
        if temps:
            avg_temp = sum(temps) / len(temps)
            print(f"   Avg temperature: {avg_temp:.1f}Â°C")
        
        # Evaluation
        print("\n" + "=" * 60)
        
        if max_temp < 75:
            print("âœ… THERMAL TEST: EXCELLENT")
            print("âœ… Cooling is very good (<75Â°C)")
            result_code = 0
        elif max_temp < 80:
            print("âœ… THERMAL TEST: PASS")
            print("âœ… Cooling is good (<80Â°C)")
            result_code = 0
        elif max_temp < temp_limit_gpu:
            print("âš ï¸  THERMAL TEST: WARNING")
            print("âš ï¸  Temperature is high but acceptable")
            print("âš ï¸  Consider thermal pad replacement (-1M VND)")
            result_code = 2  # Warning
        else:
            print("âŒ THERMAL TEST: FAIL")
            print(f"âŒ Temperature exceeded limit ({max_temp}Â°C > {temp_limit_gpu}Â°C)")
            print("âŒ Cooling system may be inadequate")
            result_code = 1
        
        if throttled:
            print("âš ï¸  Thermal throttling detected during test")
        
        print("=" * 60)
        
        # Cleanup
        del tensor_a, tensor_b, result
        torch.cuda.empty_cache()
        
        # Cool down
        print("\nğŸ§Š Cooling down (10 seconds)...")
        time.sleep(10)
        
        final_temp = get_temperature()
        if final_temp:
            print(f"   Final temperature: {final_temp}Â°C")
        
        return result_code
        
    except Exception as e:
        print(f"\nâŒ ERROR: {str(e)}")
        torch.cuda.empty_cache()
        return 1

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="RTX 3090 Thermal Test")
    parser.add_argument("--duration", type=int, default=3,
                        help="Test duration in minutes (default: 3)")
    parser.add_argument("--limit", type=int, default=85,
                        help="GPU temperature limit in Â°C (default: 85)")
    
    args = parser.parse_args()
    
    result = thermal_stress_test(args.duration, args.limit)
    
    sys.exit(result)
